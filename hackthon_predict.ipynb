{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackthon_predict.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ct6ouuEbl_Gu",
        "outputId": "a28402da-cb2f-4f60-d81b-62c3e01dffec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, utils\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWDgCfhpmSaT"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "    \n",
        "class Down(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "            \n",
        "class Up(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        \n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "            \n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "        \n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2, \n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "    \n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(Unet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "        \n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cHjDn7emDmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f21fe0c7-3597-4839-cc79-1f5ffcaede9b"
      },
      "source": [
        "path = '/content/drive/MyDrive/side_project/satellite_segmentation/hackthon/unet.pt'\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Unet(3, 2).to(device)\n",
        "# net.load_state_dict(torch.load(path)) # gpu\n",
        "net.load_state_dict(torch.load(path, map_location=device)) # cpu"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-81tuuumOHA"
      },
      "source": [
        "loader = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "\n",
        "def image_loader(image_name):\n",
        "    \"\"\"load image, returns cuda tensor\"\"\"\n",
        "    image = Image.open(image_name)\n",
        "    image = loader(image).float()\n",
        "    image = Variable(image, requires_grad=True)\n",
        "    image = image.unsqueeze(0) \n",
        "    return image # .cuda()  #assumes that you're using GPU\n",
        "\n",
        "path = '/content/drive/MyDrive/side_project/satellite_segmentation/hackthon/image/'\n",
        "saved_path = '/content/drive/MyDrive/side_project/satellite_segmentation/hackthon/predict/'\n",
        "\n",
        "for image_id in range(36, 101):\n",
        "  for i in range(8):\n",
        "    for j in range(8):\n",
        "      image_name = f'output_{image_id}_{i}_{j}.png'\n",
        "      image = image_loader(path + image_name)\n",
        "      pred = net(image)\n",
        "      pred = np.where(pred.cpu() >= 0.5, 1, 0)[0][0]\n",
        "      cv2.imwrite(saved_path + image_name, pred)\n",
        "  print(image_id, ' is done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjGQTM1wmas5"
      },
      "source": [
        "# image = Image.open(path)\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
        "# ax1.imshow(image)\n",
        "# ax2.imshow(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2DamxZrmqS1"
      },
      "source": [
        "# loader = transforms.Compose([transforms.Resize((256, 256)), transforms.ToTensor()])\n",
        "\n",
        "# def image_loader(image_name):\n",
        "#     \"\"\"load image, returns cuda tensor\"\"\"\n",
        "#     image = Image.open(image_name)\n",
        "#     image = loader(image).float()\n",
        "#     image = Variable(image, requires_grad=True)\n",
        "#     image = image.unsqueeze(0) \n",
        "#     return image # .cuda()  #assumes that you're using GPU\n",
        "\n",
        "# path = '/content/drive/MyDrive/side_project/satellite_segmentation/hackthon/image/'\n",
        "# image_name = f'output_{117}_{7}_{7}.png'\n",
        "# image = image_loader(path + image_name)\n",
        "# pred = net(image)\n",
        "# pred = np.where(pred.cpu() >= 0.5, 1, 0)[0][0]\n",
        "# image = cv2.imread(path + image_name)\n",
        "\n",
        "# fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 15))\n",
        "# ax1.imshow(image)\n",
        "# ax2.imshow(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEB8e5CXY20q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}